# Amplify Your Critical Thinking with Generative AI  (LinkedIn course)

| Term                       | Definition                                                                 |
|----------------------------|-----------------------------------------------------------------------------|
| **confirmation bias**       | A type of bias in which an individual only considers or seeks information that confirms their existing beliefs |
| **critical thinking**       | Questioning and evaluating information for reliability, relevance, and validity |
| **historical bias in Gen AI**| A type of bias arising in Gen AI because the datasets used to train the AI contain data that may reflect historical biases |
| **PIQPACC**                 | A framework designed to assist with critical thinking; the acronym stands for purpose, information, questions, perspectives, assumptions, concepts, and conclusions |
| **skepticism**              | An active, engaged form of doubt                                           |
| **truth claims**            | Conclusions that some believe are true but require context and are subject to debate |


# Historical Bias

- Data used to train AI includes texts from the internet and books.
I am a product manager concerned about losing my job to AI. 

Prompts: 

- Should I consider changing my career?
- Is the information you provide based on recent data from 2024, or could older data influence it?
- Do you have data comparing Product Managers' job security between 2023 and 2024?
- Does the career path you mention for Product Managers reflect current economic conditions, or is it based on historical trends?
- When recommending a salary for Product Managers in Spain, are you relying heavily on well-known benefits such as salary and networking, potentially overlooking other valid but less-discussed factors?

# Confirmation Bias

- Use Gen AI to challenge my decisions by suggesting alternative perspectives I might not have considered.
- Can you provide data and analysis showing whether we might unintentionally favor overly positive outcomes?

